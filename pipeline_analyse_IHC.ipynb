{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pipeline_analyse_IHC.ipynb","provenance":[],"collapsed_sections":["GgzDcWWTlkUd"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Qd-diPEpcmsI"},"source":["# Développement d’un module de classification d’images IHC par IA\r\n","\r\n","### By Maëlle Broustal, Rafik Mankour & Ian Pellet"]},{"cell_type":"markdown","metadata":{"id":"GgzDcWWTlkUd"},"source":["## Import"]},{"cell_type":"code","metadata":{"id":"X_6phcYzOena","executionInfo":{"status":"ok","timestamp":1616082699380,"user_tz":-60,"elapsed":1557,"user":{"displayName":"Ian Pellet","photoUrl":"https://lh3.googleusercontent.com/-VquyaV9apz0/AAAAAAAAAAI/AAAAAAAAAEs/jOmz2uWB17E/s64/photo.jpg","userId":"02004371459168203791"}}},"source":["import numpy as np\r\n","import pandas as pd\r\n","import skimage\r\n","import skimage.draw\r\n","import matplotlib.pyplot as plt\r\n","from xml.dom import minidom as minidom\r\n","import PIL "],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"hOORTkeUHnVh","executionInfo":{"status":"ok","timestamp":1616082734981,"user_tz":-60,"elapsed":2331,"user":{"displayName":"Ian Pellet","photoUrl":"https://lh3.googleusercontent.com/-VquyaV9apz0/AAAAAAAAAAI/AAAAAAAAAEs/jOmz2uWB17E/s64/photo.jpg","userId":"02004371459168203791"}}},"source":["from tensorflow import keras as k"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uo5efSnzOP2L","executionInfo":{"status":"ok","timestamp":1616082743472,"user_tz":-60,"elapsed":437,"user":{"displayName":"Ian Pellet","photoUrl":"https://lh3.googleusercontent.com/-VquyaV9apz0/AAAAAAAAAAI/AAAAAAAAAEs/jOmz2uWB17E/s64/photo.jpg","userId":"02004371459168203791"}}},"source":["#k.__version__"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KZ4WbK0W8Vll","executionInfo":{"status":"ok","timestamp":1616082764990,"user_tz":-60,"elapsed":595,"user":{"displayName":"Ian Pellet","photoUrl":"https://lh3.googleusercontent.com/-VquyaV9apz0/AAAAAAAAAAI/AAAAAAAAAEs/jOmz2uWB17E/s64/photo.jpg","userId":"02004371459168203791"}},"outputId":"fed5dead-fbbc-483d-ebf4-eec359e2c2ca"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AyliVi1RloZA"},"source":["### Openslide"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFW9E9bhL66w","outputId":"881fd058-599e-4940-fdcb-b23e6baeb105"},"source":["!apt update && apt install -y openslide-tools\r\n","!pip install openslide-python"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[33m\r0% [Working]\u001b[0m\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [2 InRelease 0 B/3,626 B 0%] [Wa\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\u001b[0m\u001b[33m\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\u001b[0m\r                                                                               \rGet:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","\u001b[33m\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [3 In\u001b[0m\r                                                                               \rGet:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","\u001b[33m\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 2,587 B/88.7 k\u001b[0m\r                                                                               \rIgn:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n","Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:12 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [49.4 kB]\n","Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Ign:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n","Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [603 kB]\n","0% [3 InRelease gpgv 15.9 kB]\u001b[0m"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r6mZlIIq_NA_","colab":{"base_uri":"https://localhost:8080/","height":306},"executionInfo":{"status":"error","timestamp":1616082769762,"user_tz":-60,"elapsed":703,"user":{"displayName":"Ian Pellet","photoUrl":"https://lh3.googleusercontent.com/-VquyaV9apz0/AAAAAAAAAAI/AAAAAAAAAEs/jOmz2uWB17E/s64/photo.jpg","userId":"02004371459168203791"}},"outputId":"57d18f17-d15e-433a-91ca-4dc577407a07"},"source":["import openslide"],"execution_count":7,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-bb94c1b557c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mopenslide\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openslide'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"mt0VR2iPcp_c"},"source":["## Chargement des images et annotations"]},{"cell_type":"code","metadata":{"id":"5kN-8NDE7ZyL","colab":{"base_uri":"https://localhost:8080/","height":167},"executionInfo":{"status":"error","timestamp":1615905473238,"user_tz":-60,"elapsed":1318,"user":{"displayName":"Ian Pellet","photoUrl":"https://lh3.googleusercontent.com/-VquyaV9apz0/AAAAAAAAAAI/AAAAAAAAAEs/jOmz2uWB17E/s64/photo.jpg","userId":"02004371459168203791"}},"outputId":"23619be0-c70b-4fc4-fa80-5a6f0bb5b8dc"},"source":["img_test = openslide.OpenSlide('./data/CRC1.ndpi') # open whole-slide image"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-e420dce09b1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenslide\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpenSlide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/CRC1.ndpi'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# open whole-slide image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'openslide' is not defined"]}]},{"cell_type":"code","metadata":{"id":"BwG6bLQl84Ms"},"source":["#Rafik\r\n","img_test = openslide.OpenSlide('/content/drive/MyDrive/data/CRC1.ndpi')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z_rE7wuS7wQM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615978480244,"user_tz":-60,"elapsed":482,"user":{"displayName":"Rafik Mankour","photoUrl":"","userId":"06707444341054952045"}},"outputId":"5891a575-87f4-42f3-ccf2-86524a981b03"},"source":["img_test.level_dimensions # dimensions for each levels of the slide"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((64512, 53760),\n"," (32256, 26880),\n"," (16128, 13440),\n"," (8064, 6720),\n"," (4032, 3360),\n"," (2016, 1680),\n"," (1008, 840),\n"," (504, 420),\n"," (252, 210),\n"," (126, 105))"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"AlKYxf747x36","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615978482562,"user_tz":-60,"elapsed":594,"user":{"displayName":"Rafik Mankour","photoUrl":"","userId":"06707444341054952045"}},"outputId":"5b9d753f-67b3-4841-e2b7-ad6451ada267"},"source":["img_test.level_downsamples # downsample rates of each level"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0, 256.0, 512.0)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"rmQ90GG17zwU","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1wZQUAUspwFECeVJVciKV5baHURBTNYJM"},"executionInfo":{"status":"ok","timestamp":1615978488206,"user_tz":-60,"elapsed":4625,"user":{"displayName":"Rafik Mankour","photoUrl":"","userId":"06707444341054952045"}},"outputId":"27976c8f-bf55-46ac-b76d-0c6ba4ee9be0"},"source":["img_test.get_thumbnail((1200, 1200)) # RGB image of the slide of size (1200,1200)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"sHUQsC5X73Xv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615978494348,"user_tz":-60,"elapsed":5548,"user":{"displayName":"Rafik Mankour","photoUrl":"","userId":"06707444341054952045"}},"outputId":"c07af412-d021-4e5b-b8c7-b926e63c3068"},"source":["# for each level, print level and size and open a region of the slide\r\n","max_size = (1800, 1000)\r\n","for lvl in range(img_test.level_count):\r\n","    lvl_size = img_test.level_dimensions[lvl]\r\n","    print(lvl, lvl_size)\r\n","    disp_size = max_size if lvl_size > max_size else lvl_size\r\n","\r\n","    img_test.read_region((0,0), lvl, disp_size).show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 (64512, 53760)\n","1 (32256, 26880)\n","2 (16128, 13440)\n","3 (8064, 6720)\n","4 (4032, 3360)\n","5 (2016, 1680)\n","6 (1008, 840)\n","7 (504, 420)\n","8 (252, 210)\n","9 (126, 105)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zlT_nGda74ET","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615978496415,"user_tz":-60,"elapsed":500,"user":{"displayName":"Rafik Mankour","photoUrl":"","userId":"06707444341054952045"}},"outputId":"0ad358d2-235c-4112-9122-3fd541c7e1e4"},"source":["# we can extract a region of a level of our slide \r\n","PIL_img = img_test.read_region((8000,4000), 5, (1200, 1200))\r\n","type(PIL_img)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PIL.Image.Image"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"XQS8LzxI75wN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615978499799,"user_tz":-60,"elapsed":475,"user":{"displayName":"Rafik Mankour","photoUrl":"","userId":"06707444341054952045"}},"outputId":"2623932a-c501-4fd2-c4d3-79dcd6919e3a"},"source":["np_img = np.array(PIL_img) # convert PIL Image to a Numpy array\r\n","np_img.shape # RGBA"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1200, 1200, 4)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"Xmxj1yvQ771Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615978501468,"user_tz":-60,"elapsed":469,"user":{"displayName":"Rafik Mankour","photoUrl":"","userId":"06707444341054952045"}},"outputId":"015eecfb-587a-4375-94fb-a2acc313e730"},"source":["lvl = 5 # levels 0 to 2 are to big \r\n","full_img = img_test.read_region((0,0), lvl, img_test.level_dimensions[lvl])\r\n","full_np = np.array(full_img)\r\n","full_np.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1680, 2016, 4)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"iUtNX4gL795j"},"source":["img_test.close() # close image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vjGOEJ_1eRYt"},"source":["### Annotations"]},{"cell_type":"code","metadata":{"id":"PV_hX2EHKXGz"},"source":["#pour Rafik\r\n","annot = minidom.parse(\"/content/drive/MyDrive/data/annot.annotations\") # open XML file"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eUqVkvZFW03u"},"source":["#pour Mallou\r\n","annot = minidom.parse(\"/content/drive/MyDrive/Projet 4BIM/data/annot.annotations\") # open XML file"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PAqI0ABIKd3Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615978513003,"user_tz":-60,"elapsed":469,"user":{"displayName":"Rafik Mankour","photoUrl":"","userId":"06707444341054952045"}},"outputId":"a680f420-8bb0-4daa-e2aa-5d44fcc713f1"},"source":["regions = annot.getElementsByTagName(\"Region\") # list of regions in the annotation file\r\n","print(len(regions))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["26\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KG2yqZYiKfFB"},"source":["V = [] # list of vertices in each region\r\n","V_coord = [] # list of coord of each vertex in each region\r\n","for r in regions :\r\n","  if r.getAttribute(\"NegativeROA\")=='0': \r\n","    vertices = r.getElementsByTagName(\"V\")\r\n","    V.append(vertices)\r\n","    \r\n","    v_coord = []\r\n","    for v in vertices :\r\n","        coord = {\"X\": v.getAttribute('X'), \"Y\": v.getAttribute('Y')}\r\n","        v_coord.append(coord)\r\n","    V_coord.append(v_coord)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gPLlCT_H8pfa"},"source":["#### 0/1 array representation of regions of interest"]},{"cell_type":"code","metadata":{"id":"ixyv-0weobMn"},"source":["img = np.ones((8064, 6720)) # creates an array of ones of the same shape of our image\n","ds_rate = 8 # downsample rate\n","\n","polygons = [] # list of polygons, each object is an array containing the coord of the px in a region of V_coord\n","\n","for region in V_coord:\n","  x = [] # list of x coord in the region\n","  y = [] # list of y coord in the region\n","  \n","  for v in region:\n","    # as we dont take the full resolution slide of the image, we need to divide the coord of each vertice by the downsampling rate\n","    temp_x = int(v['X'])/ds_rate \n","    temp_y = int(v['Y'])/ds_rate\n","    \n","    x.append(int(temp_x))\n","    y.append(int(temp_y))\n","\n","  # sikimage computes the coord of each px in the region from the vertices defining the perimeter of the region\n","  polygons.append(skimage.draw.polygon(x,y)) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"edaN7TQixwW-"},"source":["# modify img so that each px in a region of V_coord is set to 0\n","for p in range(len(polygons)):\n","  poly = np.transpose(polygons[p])\n","\n","  for i in range(len(poly)):\n","    img[(poly[i][0], poly[i][1])] = 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4cX-WKdUz5gJ","executionInfo":{"status":"ok","timestamp":1615978564513,"user_tz":-60,"elapsed":42561,"user":{"displayName":"Rafik Mankour","photoUrl":"","userId":"06707444341054952045"}},"outputId":"f7b9cf3c-5911-4e1e-a5f1-c5c9bac515f8"},"source":["img"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1., 1., 1., ..., 1., 1., 1.],\n","       [1., 1., 1., ..., 1., 1., 1.],\n","       [1., 1., 1., ..., 1., 1., 1.],\n","       ...,\n","       [1., 1., 1., ..., 1., 1., 1.],\n","       [1., 1., 1., ..., 1., 1., 1.],\n","       [1., 1., 1., ..., 1., 1., 1.]])"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"Z8g6QQhFczTI"},"source":["## Mise en place du réseau de neurones"]},{"cell_type":"markdown","metadata":{"id":"_Dsoi1Bby1Ny"},"source":["Adapter ce code issu des liens dans le sprint backlog avec des données :\r\n","Problème à régler -> faire correspondre la taille et la dimension de l'image ) celle de la matrice d'annotation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hdzYSUH52KKI","executionInfo":{"status":"ok","timestamp":1615982760833,"user_tz":-60,"elapsed":2078,"user":{"displayName":"Rafik Mankour","photoUrl":"","userId":"06707444341054952045"}},"outputId":"1e4c6b81-7001-4cc0-fbd4-9cf26d433871"},"source":["all_images = []\r\n","all_images.append(full_np)\r\n","\r\n","all_annotations = []\r\n","all_annotations.append(img)\r\n","\r\n","x_train = np.array(all_images)\r\n","y_train = np.array(all_annotations)\r\n","y_train = k.utils.to_categorical(y_train, 2)\r\n","\r\n","print(np.shape(x_train))\r\n","np.shape(y_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1, 1680, 2016, 4)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(1, 8064, 6720, 2)"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":795},"id":"IpcPqqdqcBl0","executionInfo":{"status":"error","timestamp":1615982816933,"user_tz":-60,"elapsed":3191,"user":{"displayName":"Rafik Mankour","photoUrl":"","userId":"06707444341054952045"}},"outputId":"a7a5edd2-1c7f-4aa0-94cf-f10b92c5d96c"},"source":["from tensorflow.keras.applications.inception_v3 import InceptionV3\r\n","from tensorflow.keras.preprocessing import image\r\n","from tensorflow.keras.models import Model\r\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\r\n","\r\n","# create the base pre-trained model\r\n","base_model = InceptionV3(weights='imagenet', include_top=False)\r\n","\r\n","# add a global spatial average pooling layer\r\n","x = base_model.output\r\n","x = GlobalAveragePooling2D()(x)\r\n","# let's add a fully-connected layer\r\n","x = Dense(1024, activation='relu')(x)\r\n","# and a logistic layer -- let's say we have 200 classes\r\n","predictions = Dense(200, activation='softmax')(x)\r\n","\r\n","# this is the model we will train\r\n","model = Model(inputs=base_model.input, outputs=predictions)\r\n","\r\n","# first: train only the top layers (which were randomly initialized)\r\n","# i.e. freeze all convolutional InceptionV3 layers\r\n","for layer in base_model.layers:\r\n","    layer.trainable = False\r\n","\r\n","# compile the model (should be done *after* setting layers to non-trainable)\r\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\r\n","\r\n","# train the model on the new data for a few epochs\r\n","\r\n","model.fit(x_train, y_train, batch_size=1, epochs=10, verbose=1)\r\n","\r\n","# at this point, the top layers are well trained and we can start fine-tuning\r\n","# convolutional layers from inception V3. We will freeze the bottom N layers\r\n","# and train the remaining top layers.\r\n","\r\n","# let's visualize layer names and layer indices to see how many layers\r\n","# we should freeze:\r\n","for i, layer in enumerate(base_model.layers):\r\n","   print(i, layer.name)\r\n","\r\n","# we chose to train the top 2 inception blocks, i.e. we will freeze\r\n","# the first 249 layers and unfreeze the rest:\r\n","for layer in model.layers[:249]:\r\n","   layer.trainable = False\r\n","for layer in model.layers[249:]:\r\n","   layer.trainable = True\r\n","\r\n","# we need to recompile the model for these modifications to take effect\r\n","# we use SGD with a low learning rate\r\n","from tensorflow.keras.optimizers import SGD\r\n","model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\r\n","\r\n","# we train our model again (this time fine-tuning the top 2 inception blocks\r\n","# alongside the top Dense layers\r\n","\r\n","model.fit(x_train, y_train, batch_size=1, epochs=10, verbose=1)\r\n","\r\n","# FOURNIR X_TRAIN AVEC LES IMAGES et Y_TRAIN AVEC LES ANNOTATIONS A EMPLOYER\r\n","\r\n","for i, layer in enumerate(base_model.layers):\r\n","   print(i, layer.name)\r\n","\r\n","# we chose to train the top 2 inception blocks, i.e. we will freeze\r\n","# the first 249 layers and unfreeze the rest:\r\n","for layer in model.layers[:249]:\r\n","   layer.trainable = False\r\n","for layer in model.layers[249:]:\r\n","   layer.trainable = True\r\n","\r\n","# we need to recompile the model for these modifications to take effect\r\n","# we use SGD with a low learning rate\r\n","from tensorflow.keras.optimizers import SGD\r\n","model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\r\n","\r\n","# we train our model again (this time fine-tuning the top 2 inception blocks\r\n","# alongside the top Dense layers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-20b1e1652858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# train the model on the new data for a few epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# at this point, the top layers are well trained and we can start fine-tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer model_13: expected shape=(None, None, None, 3), found shape=(1, 1680, 2016, 4)\n"]}]},{"cell_type":"markdown","metadata":{"id":"RKRYUBWKc6BN"},"source":["## Test du réseau de neurones"]},{"cell_type":"code","metadata":{"id":"DWZnFaSDc9Zq"},"source":[""],"execution_count":null,"outputs":[]}]}